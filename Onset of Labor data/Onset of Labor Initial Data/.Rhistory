# Using PCA to project the points on a 2D surface
imp <- cbind.data.frame(res.comp$completeObs,patient_clusters)
res.pca <- PCA(imp, quanti.sup = 1, quali.sup = dim(imp)[2], ncp = nb$ncp, graph=FALSE)
# Dataframes for plot
projected_coord <- cbind(res.pca$ind$coord[,c("Dim.1", "Dim.2")], patient_clusters)
df_coord <- as.data.frame(projected_coord) %>%
rownames_to_column("ID") %>%
dplyr::filter(!grepl("centroid", ID)) %>%
dplyr::mutate(Dim.1=as.double(Dim.1), Dim.2=as.double(Dim.2))
df_centroid <- as.data.frame(projected_coord) %>%
rownames_to_column("ID") %>%
dplyr::filter(grepl("centroid", ID))%>%
dplyr::mutate(Dim.1=as.double(Dim.1), Dim.2=as.double(Dim.2))
# Plot with all the points
p1 <- ggplot() +
geom_point(data=df_centroid, aes(x=Dim.1, y=Dim.2, color=patient_clusters, shape="Drug assay centroids"), size=3) +
geom_point(data=df_coord, aes(x=Dim.1, y=Dim.2, color=patient_clusters, shape="OOL patients")) +
scale_shape_manual(name = "Patients", values = c("OOL patients" = 21, "Drug assay centroids" = 8)) +
guides(shape = guide_legend(title = "Patients", order=2), color=guide_legend(title = "Clusters", order=1)) +
#scale_x_continuous(limits=c(-5, 5), expand=c(0., 0.)) +
#scale_y_continuous(limits=c(-3, 3), expand=c(0., 0.)) +
ggtitle("Projection of patient clustering on 2 first dimensions of PCA analysis") +
theme_minimal()
# Plot with only the centroids
p2 <- ggplot() +
geom_point(data=df_centroid, aes(x=Dim.1, y=Dim.2, color=patient_clusters, shape="Drug assay centroids"), size=3) +
scale_shape_manual(name = "Patients", values = c("OOL patients" = 21, "Drug assay centroids" = 8)) +
guides(shape = guide_legend(title = "Patients", order=2), color=guide_legend(title = "Clusters", order=1)) +
#scale_x_continuous(limits=c(-5, 5), expand=c(0., 0.)) +
#scale_y_continuous(limits=c(-3, 3), expand=c(0., 0.)) +
ggtitle("Projection of centroids on 2 first dimensions of PCA analysis") +
theme_minimal()
# Creating new directory
if (!file.exists(paste0(my_path, "/Plots/Clustering"))){dir.create(paste0(my_path, "/Plots/Clustering"), recursive = TRUE)}
# Saving the clustering plots
pdf(paste0(my_path, "/Plots/Clustering/Projection of patient clustering with PCA dim1&2.pdf"), height=5, width=7)
p1
p2
dev.off()
# Concatenating all simulated predictions
all.simulated.predictions <- c()
col_names <- c("drug", "sampleID", "centroid", "dose", "TTL.prediction")
for (i in 1:length(prdC)){
all.simulated.predictions <- rbind(all.simulated.predictions,
prdC[[i]]$median.simulated.TTL %>% rename_with(~ col_names, everything()),
prdC[[i]]$individual.simulated.TTL %>% rename_with(~ col_names, everything()))
}
# Only keeping the rows where centroid is median or where the sampleID is associated to the centroid it has been clustered with
all.simulated.predictions = all.simulated.predictions %>%
rowwise() %>%
dplyr::mutate(extracted_number = str_extract(sampleID, "\\d+")) %>%
dplyr::filter((centroid == "median") || (extracted_number %in% unlist(clusters[as.integer(centroid)]))) %>%
ungroup() %>%
select(-extracted_number)
plot_delay_distribution <- function(c_k, centroid.val="median", EGA.inf=0, EGA.sup=40){
# Filtering the samples corresponding to EGA between EGA.inf and EGA.sup days
filter.ID <- subset(read_csv(paste0(OOL_path, "/Preprocessed Data/EGA_OOL.csv"), show_col_types = FALSE),
EGA >= EGA.inf & EGA <= EGA.sup,
select = ID)$ID
# Getting the simulated predictions
drug_dose_simulated_predictions <- dplyr::filter(all.simulated.predictions, (centroid==centroid.val)&(dose==10^(c_k-1))) %>%
pivot_wider(names_from = drug, values_from = TTL.prediction) %>% column_to_rownames("sampleID") %>%
dplyr::select(-c(centroid, dose))
# Getting the row numbers of the predictions corresponding to simulated.data
row_numbers <- which(data$ID %in% filter.ID)
# TTL predictions
TTL.predictions <- matrix(list_preds[[model.name]][row_numbers],
nrow = length(row_numbers),
ncol = dim(drug_dose_simulated_predictions)[2],
dimnames = list(filter.ID, colnames(drug_dose_simulated_predictions)))
# Difference between the TTL predictions and the TTL predictions with simulated drug effect
drug.effect.on.predictions <- - (drug_dose_simulated_predictions[filter.ID,] - TTL.predictions[filter.ID,])
# Looking at the distributions of the drug simulated effect in term of days on the TTL prediction
plot.data <- as.data.frame(drug.effect.on.predictions)
# Reshape data into long format
plot.data_long <- gather(plot.data, key = "drug", value = "value")
# Plot distributions
p <- ggplot(plot.data_long, aes(x = value, fill = drug)) +
geom_density(alpha = 0.5) +
xlab("Delay (in days)") +
geom_vline(xintercept = 0, linetype = "dashed") +
ggtitle(paste0("Dose ", 10^(c_k-1))) +
theme_minimal()
plot(p)
}
# Creating a new directory
if (!file.exists(paste0(my_path, "/Plots/Drug effect delay distributions"))){dir.create(paste0(my_path, "/Plots/Drug effect delay distributions"))}
# Plotting all the combinations of plots possible
for (centroid.val in unique(all.simulated.predictions$centroid)){
pdf(paste0(my_path, "/Plots/Drug effect delay distributions/Delay distribution for ", ifelse(centroid.val=="median","median effect", paste("cluster",centroid.val)), ".pdf"))
for (c_k in 1:4){
plot_delay_distribution(c_k, centroid.val, 0, 40)
}
dev.off()
}
plot_delay_distribution <- function(c_k, centroid.val="median", EGA.inf=0, EGA.sup=40){
# Filtering the samples corresponding to EGA between EGA.inf and EGA.sup days
filter.ID <- subset(read_csv(paste0(OOL_path, "/Preprocessed Data/EGA_OOL.csv"), show_col_types = FALSE),
EGA >= EGA.inf & EGA <= EGA.sup,
select = ID)$ID
# Getting the simulated predictions
drug_dose_simulated_predictions <- dplyr::filter(all.simulated.predictions, (centroid==centroid.val)&(dose==10^(c_k-1))) %>%
pivot_wider(names_from = drug, values_from = TTL.prediction) %>% column_to_rownames("sampleID") %>%
dplyr::select(-c(centroid, dose))
# Getting the row numbers of the predictions corresponding to simulated.data
row_numbers <- which(data$ID %in% filter.ID)
# TTL predictions
TTL.predictions <- matrix(list_preds[[model.name]][row_numbers],
nrow = length(row_numbers),
ncol = dim(drug_dose_simulated_predictions)[2],
dimnames = list(filter.ID, colnames(drug_dose_simulated_predictions)))
# Difference between the TTL predictions and the TTL predictions with simulated drug effect
drug.effect.on.predictions <- - (drug_dose_simulated_predictions[filter.ID,] - TTL.predictions[filter.ID,])
# Looking at the distributions of the drug simulated effect in term of days on the TTL prediction
plot.data <- as.data.frame(drug.effect.on.predictions)
# Reshape data into long format
plot.data_long <- gather(plot.data, key = "drug", value = "value")
# Plot distributions
p <- ggplot(plot.data_long, aes(x = value, fill = drug)) +
geom_density(alpha = 0.5) +
xlab("Delay (in days)") +
geom_vline(xintercept = 0, linetype = "dashed") +
ggtitle(paste0("Dose ", 10^(c_k-1))) +
theme_minimal()
plot(p)
}
# Creating a new directory
if (!file.exists(paste0(my_path, "/Plots/Drug effect delay distributions"))){dir.create(paste0(my_path, "/Plots/Drug effect delay distributions"))}
# Plotting all the combinations of plots possible
for (centroid.val in unique(all.simulated.predictions$centroid)){
pdf(paste0(my_path, "/Plots/Drug effect delay distributions/Delay distribution for ", ifelse(centroid.val=="median","median effect", paste("cluster",centroid.val)), ".pdf"))
for (c_k in 1:4){
plot_delay_distribution(c_k, centroid.val, 25, 35)
}
dev.off()
}
plot_delay_distribution <- function(c_k, centroid.val="median", EGA.inf=0, EGA.sup=40){
# Filtering the samples corresponding to EGA between EGA.inf and EGA.sup days
filter.ID <- subset(read_csv(paste0(OOL_path, "/Preprocessed Data/EGA_OOL.csv"), show_col_types = FALSE),
EGA >= EGA.inf & EGA <= EGA.sup,
select = ID)$ID
# Getting the simulated predictions
drug_dose_simulated_predictions <- dplyr::filter(all.simulated.predictions, (centroid==centroid.val)&(dose==10^(c_k-1))) %>%
pivot_wider(names_from = drug, values_from = TTL.prediction) %>% column_to_rownames("sampleID") %>%
dplyr::select(-c(centroid, dose))
# Getting the row numbers of the predictions corresponding to simulated.data
row_numbers <- which(data$ID %in% filter.ID)
# TTL predictions
TTL.predictions <- matrix(list_preds[[model.name]][row_numbers],
nrow = length(row_numbers),
ncol = dim(drug_dose_simulated_predictions)[2],
dimnames = list(filter.ID, colnames(drug_dose_simulated_predictions)))
# Difference between the TTL predictions and the TTL predictions with simulated drug effect
drug.effect.on.predictions <- - (drug_dose_simulated_predictions[filter.ID,] - TTL.predictions[filter.ID,])
# Looking at the distributions of the drug simulated effect in term of days on the TTL prediction
plot.data <- as.data.frame(drug.effect.on.predictions)
# Reshape data into long format
plot.data_long <- gather(plot.data, key = "drug", value = "value")
# Plot distributions
p <- ggplot(plot.data_long, aes(x = value, fill = drug)) +
geom_density(alpha = 0.5) +
xlab("Delay (in days)") +
geom_vline(xintercept = 0, linetype = "dashed") +
ggtitle(paste0("Dose ", 10^(c_k-1))) +
theme_minimal()
plot(p)
}
# Creating a new directory
if (!file.exists(paste0(my_path, "/Plots/Drug effect delay distributions"))){dir.create(paste0(my_path, "/Plots/Drug effect delay distributions"))}
# Plotting all the combinations of plots possible
for (centroid.val in unique(all.simulated.predictions$centroid)){
pdf(paste0(my_path, "/Plots/Drug effect delay distributions/Delay distribution for ", ifelse(centroid.val=="median","median effect", paste("cluster",centroid.val)), ".pdf"))
for (c_k in 1:4){
plot_delay_distribution(c_k, centroid.val, 25, 30)
}
dev.off()
}
data %>% dplyr::filter(DOS >= 37)
data %>% dplyr::filter(DOS >= 36)
data %>% dplyr::filter(DOS >= 35)
data %>% dplyr::filter(DOS >= 30)
data
# Getting CYTOF with EGA
CYTOF_EGA <- dplyr::select(data, -DOS)
list_preds
list_preds[[model.name]]
EGA
data$ID
preterm_rows
TTL.pred_EGA <- data.frame(TTL.pred=list_preds[[model.name]], EGA=EGA)
TTL.pred_EGA
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA)
TTL.pred_EGA
preterm_ID
library(stringr)
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
dplyr::mutate(preterm=ifelse(any(str_detect(ID, preterm_ID), 1, 0)))
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
dplyr::mutate(preterm=ifelse(any(str_detect(ID, preterm_ID)), 1, 0))
ID
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
dplyr::mutate(new_column = ifelse(any(str_detect(ID, preterm_ID)), 1, 0))
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
dplyr::mutate(new_column = ifelse(any(sapply(preterm_ID, str_detect, string = ID)), 1, 0))
TTL.pred_EGA
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
rowwise() %>%
dplyr::mutate(preterm = ifelse(any(str_detect(preterm_ID, ID)), 1, 0)) %>%
ungroup()
TTL.pred_EGA
preterm_ID
TTL.pred_EGA
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
rowwise() %>%
dplyr::mutate(preterm = ifelse(any(str_detect(ID, preterm_ID)), 1, 0)) %>%
ungroup()
TTL.pred_EGA
preterm_ID
install.packages("e1071")
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
rowwise() %>%
dplyr::mutate(preterm = ifelse(any(str_detect(ID, preterm_ID)), 1, 0)) %>%
ungroup()
current_dir <- getwd()
my_path <- sub("/[^/]+$", "", current_dir)
setwd(paste0(my_path,"/Rscripts"))
OOL_path=paste0(my_path,"/Onset of Labor data")
drug_assay_path=paste0(my_path,"/Drug assay data")
out_path=paste0(OOL_path,"/Prediction model")
plot_path=paste0(my_path,"/Plots/Onset of Labor prediction model")
if(!file.exists(out_path)){dir.create(out_path, recursive = TRUE)}
if(!file.exists(plot_path)){dir.create(plot_path, recursive = TRUE)}
library(doSNOW)
library(parallel)
library(matrixStats)
library(zoo)
library(ggVennDiagram)
library(tidyverse)
library(readxl)
library(dplyr)
library(tibble)
library(stats)
require(Metrics)
library(missMDA)
library(stringr)
library(FactoMineR)
set.seed(2018)
preprocessing <- function(dataset, NA_threshold, std_threshold){
prepro_data <- dataset
cols <- colnames(dataset)
# Removing columns with proportion of missing values above NA_threshold
rm_cols <- c()
for (col_name in cols[!cols %in% "ID"]){
na_count <- sum(is.na(prepro_data[[col_name]]))
if (na_count/length(prepro_data[[col_name]]) > NA_threshold){
rm_cols[length(rm_cols)+1] <- col_name
}
}
prepro_data <- prepro_data[,!colnames(prepro_data) %in% rm_cols]
cols <- colnames(prepro_data)
# Imputing missing values with median of the colum
for (col_name in cols[!cols %in% "ID"]){
median <- median(prepro_data[[col_name]], na.rm = TRUE)
prepro_data[[col_name]][is.na(prepro_data[[col_name]])] <- median
}
# Removing columns with standard deviation below std_threshold
keep_cols <- which(colSds(as.matrix(prepro_data[,-which(names(prepro_data) == "ID")]))>std_threshold)
prepro_data <- prepro_data[,names(keep_cols)]
return(prepro_data)
}
# median.simulated.data
if (file.exists(paste0(OOL_path, "/Simulated Data/median simulated data.rda"))){
load(paste0(OOL_path, "/Simulated Data/median simulated data.rda"))
}
# individual.simulated.data
if (file.exists(paste0(OOL_path, "/Simulated Data/individual simulated data.rda"))){
load(paste0(OOL_path, "/Simulated Data/individual simulated data.rda"))
}
# Outcomes
Yh <- read_csv(paste0(OOL_path, "/Preprocessed Data/outcome_OOL.csv"), show_col_types = FALSE)
# CYTOF data
CYTOF <- read_csv(paste0(OOL_path, "/Preprocessed Data/immunome_EGA_pen_OOL.csv"), show_col_types = FALSE)
# Reorordering and filtering CYTOF data
data <- left_join(Yh, CYTOF, by="ID")
preterm_rows <- which(grepl(paste(c("P17_", "P8_", "P3_", "P5_", "P27_"), collapse = "|"), data$ID))
CYTOF <- dplyr::select(data, -DOS)
CYTOF <- dplyr::select(CYTOF, -EGA) # Removing EGA
Yh <- data$DOS
EGA <- data$EGA
# Preprocessing
CYTOF <- preprocessing(CYTOF, 0.2, 0.)
# Patients Id
Id <- as.factor(str_extract(data[["ID"]], "(?<=P)\\d+"))
# listr
load(paste0(out_path, "/Pvalue threshold optimization.rda"))
# Reshaping listr for plotting
listr <- as.data.frame(listr) %>%
pivot_longer(cols = c("Lasso.1se","Ridge.Regression","ElasticNet","Adaptive.Lasso","Random.Forest"),
names_to = "model", values_to = "speamanr")
# Find the p-value threshold with the highest Spearman's correlation score
best_forest_threshold <- listr[listr$model=="Random.Forest",]$pval_threshold[which.max(listr[listr$model=="Random.Forest",]$speamanr)]
best_lasso_threshold <- listr[listr$model=="Lasso.1se",]$pval_threshold[which.max(listr[listr$model=="Lasso.1se",]$speamanr)]
best_EN_threshold <- listr[listr$model=="ElasticNet",]$pval_threshold[which.max(listr[listr$model=="ElasticNet",]$speamanr)]
best_ridge_threshold <- listr[listr$model=="Ridge.Regression",]$pval_threshold[which.max(listr[listr$model=="Ridge.Regression",]$speamanr)]
best_alasso_threshold <- listr[listr$model=="Adaptive.Lasso",]$pval_threshold[which.max(listr[listr$model=="Adaptive.Lasso",]$speamanr)]
# Plot
p <- ggplot(listr, aes(x = pval_threshold, y = speamanr, color = model)) +
geom_line() +
geom_segment(x = best_forest_threshold, xend = best_forest_threshold, y = 0., yend=max(listr$best_r_score)+0.01, linetype = "dashed") +
geom_segment(x = best_lasso_threshold, xend = best_lasso_threshold, y = 0., yend=max(listr$best_r_score)+0.01, linetype = "dashed") +
geom_segment(x = best_ridge_threshold, xend = best_ridge_threshold, y = 0., yend=max(listr$best_r_score)+0.01, linetype = "dashed") +
geom_segment(x = best_EN_threshold, xend = best_EN_threshold, y = 0., yend=max(listr$best_r_score)+0.01, linetype = "dashed") +
geom_segment(x = best_alasso_threshold, xend = best_alasso_threshold, y = 0., yend=max(listr$best_r_score)+0.01, linetype = "dashed") +
labs(x = "p-value Threshold", y = "Spearman's correlation") +
ggtitle("Spearman's Correlation Scores by Model") +
theme_minimal() +
annotate("text", x = best_forest_threshold + 0.045, y = max(listr$best_r_score)+0.01, label = best_forest_threshold, size = 3, vjust = -1) +
annotate("text", x = best_alasso_threshold + 0.05, y = max(listr$best_r_score)+0.02, label = best_alasso_threshold, size = 3, vjust = -1) +
annotate("text", x = best_ridge_threshold + 0.04, y = max(listr$best_r_score)+0.015, label = best_ridge_threshold, size = 3, vjust = -1) +
annotate("text", x = best_lasso_threshold , y = max(listr$best_r_score)+0.01, label = best_lasso_threshold, size = 3, vjust = -1) +
annotate("text", x = best_EN_threshold, y = max(listr$best_r_score)+0.015, label = best_EN_threshold, size = 3, vjust = -1)
# Saving plot
pdf(paste0(plot_path, "/Optimization of pvalue filtering.pdf"), height=5, width=7)
p
dev.off()
best_pval_thresholds <- list("Lasso.1se"=best_lasso_threshold,
"Ridge.Regression"=best_ridge_threshold,
"ElasticNet"=best_EN_threshold,
"Adaptive.Lasso"=best_alasso_threshold,
"Random.Forest"=best_forest_threshold)
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
rowwise() %>%
dplyr::mutate(preterm = ifelse(any(str_detect(ID, preterm_ID)), 1, 0)) %>%
ungroup()
TTL.pred_EGA
library(e1071)
install.packages("caret")
library(caret)
splitIndex <- createDataPartition(TTL.pred_EGA$preterm, p = 0.7, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
train_data
TTL.pred_EGA
splitIndex <- createDataPartition(TTL.pred_EGA$preterm, p = 0.7, list = FALSE)
train_data <- TTL.pred_EGA[splitIndex, ]
test_data <- TTL.pred_EGA[-splitIndex, ]
train_data
test_data
# Train SVM
svm_model <- svm(preterm ~ ., data = train_data, kernel = "linear", cost = 1)
# Predictions
predictions <- predict(svm_model, newdata = test_data)
test_data
train_data
train_data
test_data_features <- test_data %>% dplyr::select(-preterm)
# Predictions
predictions <- predict(svm_model, newdata = test_data_features)
test_data_features
train_data
test_data_features <- test_data %>% dplyr::select(-preterm, -ID)
test_data_features
# Predictions
predictions <- predict(svm_model, newdata = test_data_features)
test_data_features
test_data_features <- test_data %>% dplyr::select(-preterm, -ID)
# Predictions
predictions <- predict(svm_model, newdata = test_data_features)
# Predictions
predictions <- predict(svm_model, newdata = test_data)
print(dim(train_data))
print(dim(test_data))
print(dim(train_data))
print(dim(test_data))
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
rowwise() %>%
dplyr::mutate(preterm = ifelse(any(str_detect(ID, preterm_ID)), 1, 0)) %>%
ungroup() %>%
dplyr::select(-ID)
splitIndex <- createDataPartition(TTL.pred_EGA$preterm, p = 0.7, list = FALSE)
train_data <- TTL.pred_EGA[splitIndex, ]
test_data <- TTL.pred_EGA[-splitIndex, ]
# Train SVM
svm_model <- svm(preterm ~ ., data = train_data, kernel = "linear", cost = 1)
# Predictions
predictions <- predict(svm_model, newdata = test_data)
# Confusion matrix
confusion_matrix <- table(predictions, test_data$target)
# Confusion matrix
confusion_matrix <- table(predictions, test_data$preterm)
print(confusion_matrix)
print(confusion_matrix)
# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
# Train SVM
tuned_parameters <- tune.svm(target ~ ., data = train_data, kernel = "linear", ranges = list(cost = c(0.01, 1, 100)))
# Train SVM
tuned_parameters <- tune.svm(preterm ~ ., data = train_data, kernel = "linear", ranges = list(cost = c(0.01, 1, 100)))
library(e1071)
library(caret)
TTL.pred_EGA <- data.frame(ID=data$ID, TTL.pred=list_preds[[model.name]], EGA=EGA) %>%
rowwise() %>%
dplyr::mutate(preterm = ifelse(any(str_detect(ID, preterm_ID)), 1, 0)) %>%
ungroup() %>%
dplyr::select(-ID)
splitIndex <- createDataPartition(TTL.pred_EGA$preterm, p = 0.7, list = FALSE)
train_data <- TTL.pred_EGA[splitIndex, ]
test_data <- TTL.pred_EGA[-splitIndex, ]
# Train Random Forest
tuned_parameters <- tuneRF(preterm ~ ., data = train_data, ntreeTry = 100)  # Tune the number of trees
current_dir <- getwd()
my_path <- sub("/[^/]+$", "", current_dir)
setwd(paste0(my_path,"/Rscripts"))
current_dir
my_path
my_path <-"/Users/jonasamar/Desktop/Drug-Assay-Study/Onset of Labor data/Onset of Labor Initial Data"
setwd(paste0(my_path))
cohort2=read_csv(paste0(my_path, "/Onset of Labor Study 2nd Cohort Reanalysis Drug Assay - Statistics.csv"))
cohort2=read.csv(paste0(my_path, "/Onset of Labor Study 2nd Cohort Reanalysis Drug Assay - Statistics.csv"))
cohort2
cohort1=read.csv(paste0(my_path, "/Onset of Labor Study Reanalysis PTB drug assay matching gates.csv"))
cohort1
cohort2
cohort1=read.csv(paste0(my_path, "/Onset of Labor Study 1st Cohort Reanalysis Drug Assay - Statistics.csv"))
cohort1=read.csv(paste0(my_path, "/Onset of Labor Study 1st Cohort Reanalysis Drug Assay - Statistics.csv"))
cohort2=read.csv(paste0(my_path, "/Onset of Labor Study 2nd Cohort Reanalysis Drug Assay - Statistics.csv"))
cohort1
cohort2
colnames(cohort1)
colnames(cohort2)
colnames(cohort1)
colnames(cohort2)
str(cohort1)
str(cohort2)
str(cohort2 %>% rename("sampleID"="ID"))
library(dplyr)
str(cohort2 %>% rename("sampleID"="ID"))
str(cohort2 %>% rename("ID"="sampleID"))
str(cohort2 %>% rename("ID"="sampleID") %>% dplyr::select(colnames(cohort1)))
cohort2 %>% rename("ID"="sampleID")
str(cohort2 %>% rename("ID"="sampleID", "Stims=stimulation") %>% dplyr::select(colnames(cohort1)))
str(cohort2 %>% rename("ID"="sampleID", "Stims"="stimulation") %>% dplyr::select(colnames(cohort1)))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.int(DOS))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=integer(DOS))
as.integer("6")
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS, na.rm=T))
str(cohort1bis)
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS))
str(cohort1bis)
str(cohort2 %>% rename("ID"="sampleID", "Stims"="stimulation") %>% dplyr::select(colnames(cohort1)))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS),
EGA=as.numeric(EGA),
median=as.numeric(median))
str(cohort1bis)
cohort2bis = cohort2 %>% rename("ID"="sampleID", "Stims"="stimulation") %>% dplyr::select(colnames(cohort1))
str(cohort2bis)
str(cohort2bis)
length(unique(cohort1bis$population))
length(unique(cohort2bis$population))
setdiff(unique(cohort1bis$population), unique(cohort2bis$population))
setdiff(unique(cohort2bis$population), unique(cohort1bis$population))
length(unique(cohort2bis$reagent))
length(unique(cohort1bis$reagent))
setdiff(unique(cohort2bis$reagent), unique(cohort1bis$reagent))
setdiff(unique(cohort1bis$reagent), unique(cohort2bis$reagent))
length(unique(cohort1bis$ID))
length(unique(cohort2bis$ID))
setdiff(unique(cohort1bis$ID), unique(cohort2bis$ID))
setdiff(unique(cohort2bis$ID), unique(cohort1bis$ID))
setdiff(unique(cohort1bis$ID), unique(cohort2bis$ID))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS),
EGA=as.numeric(EGA),
median=as.numeric(median))
%>% dplyr::filter(!(ID=="internalcontrol"))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS),
EGA=as.numeric(EGA),
median=as.numeric(median)) %>%
dplyr::filter(!(ID=="internalcontrol"))
cohort2bis = cohort2 %>% rename("ID"="sampleID", "Stims"="stimulation") %>% dplyr::select(colnames(cohort1)) %>% dplyr::filter(!(ID=="InternalControl"))
length(unique(cohort2bis$ID))
length(unique(cohort1bis$ID))
setdiff(unique(cohort1bis$ID), unique(cohort2bis$ID))
setdiff(unique(cohort2bis$ID), unique(cohort1bis$ID))
length(unique(cohort1bis$Stims))
length(unique(cohort2bis$Stims))
setdiff(unique(cohort2bis$Stims), unique(cohort1bis$Stims))
setdiff(unique(cohort1bis$Stims), unique(cohort2bis$Stims))
cohort1bis = cohort1 %>% dplyr::mutate(DOS=as.integer(DOS),
EGA=as.numeric(EGA),
median=as.numeric(median)) %>%
dplyr::filter(!(ID=="internalcontrol"))
cohort2bis = cohort2 %>% rename("ID"="sampleID", "Stims"="stimulation") %>% dplyr::select(colnames(cohort1)) %>% dplyr::filter(!(ID=="InternalControl")) %>%
dplyr::mutate(Stims=ifelse(Stims=="Unstim", "unstim", Stims))
length(unique(cohort2bis$Stims))
length(unique(cohort1bis$Stims))
setdiff(unique(cohort1bis$Stims), unique(cohort2bis$Stims))
setdiff(unique(cohort2bis$Stims), unique(cohort1bis$Stims))
cohort = rbind(cohort1bis, cohort2bis)
str(cohort)
str(cohort1)
str(cohort2)
str(cohort1)
str(cohort)
str(cohort2bis)
str(cohort1bis)
str(cohort)
write.csv(cohort, paste0(my_path, "/Onset of Labor Study Reanalysis PTB drug assay matching gates.csv"))
write.csv(cohort, paste0(my_path, "/Onset of Labor Study Reanalysis PTB drug assay matching gates.csv"), rownames=F)
write.csv(cohort, paste0(my_path, "/Onset of Labor Study Reanalysis PTB drug assay matching gates.csv"), row.names=F)
