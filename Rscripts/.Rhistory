ret$ridge_ptrain1 = predict(ridge_cv, XX, s=ridge_cv$lambda.min)
ret$ridge_coef = coef(ridge_cv, s=ridge_cv$lambda.min)[-1]
# Adaptive LASSO
alasso1_cv = cv.glmnet(x = XX, y = YY, standardize=F, foldid = fld, alpha = 1,
penalty.factor = 1 / abs(ret$ridge_coef),
keep = TRUE)
ret$alasso_p1 = predict(alasso1_cv, XT, s=alasso1_cv$lambda.min)
ret$alasso_ptrain1 = predict(alasso1_cv, XX, s=alasso1_cv$lambda.min)
ret$alasso_coef = coef(alasso1_cv, s=alasso1_cv$lambda.min)[-1]
# Random Forest
rd_forest_cv = randomForest(x = XX, y = YY, standardize=F, importance=TRUE)
ret$rd_forest_p1 = predict(rd_forest_cv, XT)
ret$rd_forest_ptrain1 = predict(rd_forest_cv, XX)
ret$rd_forest_importance = rd_forest_cv$importance
if (predict.simulated.data){
# Getting X before scaling but only with the features which were filtered
unscaled.X = original.X[,!(colnames(original.X) %in% ret$rm_cols)]
means = colMeans(unscaled.X)
sds = colSds(unscaled.X)
# Filtering the samples of the patients in the test set
ret$median.simulated.TTL <- subset(median.simulated.data, grepl(paste0("P",unique(foldid)[i],"_"),sampleID))
ret$individual.simulated.TTL <- subset(individual.simulated.data, grepl(paste0("P",unique(foldid)[i],"_"),sampleID))
# Applying CYTOF preprocessing to the median simulated data
median_prepro_data <- dplyr::select(ret$median.simulated.TTL, -c(drug, sampleID, centroid, dose)) %>%
# Removing the columns which were removed in CYTOF
dplyr::select(intersect(colnames(original.X),colnames(ret$median.simulated.TTL)), -names(ret$rm_cols)) %>%
# Imputing the missing values with the medians of the corresponding CYTOF columns
dplyr::mutate(across(everything(), ~ ifelse(is.na(.), median(CYTOF[[cur_column()]], na.rm = TRUE), .))) %>%
# Applying the patient and gobal scaling applyed to the training data
dplyr::mutate(across(everything(), ~ (. - patient.col.means[[cur_column()]] - means[[cur_column()]])/sds[[cur_column()]])) %>%
# Converting to a matrix
as.matrix()
# Applying CYTOF preprocessing to the individual simulated data
individual_prepro_data <- dplyr::select(ret$individual.simulated.TTL, -c(drug, sampleID, centroid, dose)) %>%
# Removing the columns which were removed in CYTOF
dplyr::select(intersect(colnames(original.X),colnames(ret$individual.simulated.TTL)), -names(ret$rm_cols)) %>%
# Imputing the missing values with the medians of the corresponding CYTOF columns
dplyr::mutate(across(everything(), ~ ifelse(is.na(.), median(CYTOF[[cur_column()]], na.rm = TRUE), .))) %>%
# Applying the patient and gobal scaling applyed to the training data
dplyr::mutate(across(everything(), ~ (. - patient.col.means[[cur_column()]] - means[[cur_column()]])/sds[[cur_column()]])) %>%
# Converting to a matrix
as.matrix()
# Predictions
if (parm$predict.model == "Random.Forest"){
median_predictions <- predict(rd_forest_cv, median_prepro_data)
individual_predictions <- predict(rd_forest_cv, individual_prepro_data)
}else if(parm$predict.model == "ElasticNet"){
median_predictions <- predict(EN_cv, median_prepro_data, s=EN_cv$lambda.min)
individual_predictions <- predict(EN_cv, individual_prepro_data, s=EN_cv$lambda.min)
}else if(parm$predict.model == "Lasso.1se"){
median_predictions <- predict(cvglm, median_prepro_data, s='lambda.1se')
individual_predictions <- predict(cvglm, individual_prepro_data, s='lambda.1se')
}else if(parm$predict.model == "Ridge.Regression"){
median_predictions <- predict(ridge_cv, median_prepro_data, s=ridge_cv$lambda.min)
individual_predictions <- predict(ridge_cv, individual_prepro_data, s=ridge_cv$lambda.min)
}else if(parm$predict.model == "Adaptive.Lasso"){
median_predictions <- predict(alasso1_cv, median_prepro_data, s=alasso1_cv$lambda.min)
individual_predictions <- predict(alasso1_cv, individual_prepro_data, s=alasso1_cv$lambda.min)
}else{
median_predictions <- rep(NA, dim(median_prepro_data)[0])
individual_predictions <- rep(NA, dim(individual_prepro_data)[0])
}
ret$median.simulated.TTL <-cbind(dplyr::select(ret$median.simulated.TTL, c(drug, sampleID, centroid, dose)),
median_predictions)
ret$individual.simulated.TTL <-cbind(dplyr::select(ret$individual.simulated.TTL, c(drug, sampleID, centroid, dose)),
individual_predictions)
}
return(ret)
}
# Getting the intersection of all selected features by the 5 models
best.features <- unique(AllPenDoseresponse$feature)
for (model.name in names(best_pval_thresholds)){
feature.index <- get.feature.index(model.name)
selected.features <- feature.index[feature.index[,"model_index"]>0, "feature"]
best.features <- intersect(best.features, selected.features)
}
# Saving the list of features selected by all models
save(feature.index, file=paste0(out_path, "/feature_index.rda"))
# Extracting the CYTOF dataset restricted to these features
restricted.CYTOF <- dplyr::select(CYTOF, best.features)
res <- xxx(data.matrix(restricted.CYTOF), Yh, Id, 10, parm, TRUE)
for (i in 1:53){
print(i)
res <- xxx(data.matrix(restricted.CYTOF), Yh, Id, 10, parm, TRUE)
}
xxx<-function(X, Y, foldid, i, parm, predict.simulated.data=FALSE)
{
suppressMessages(library(randomForest, quietly = TRUE))
suppressMessages(library(glmnet, quietly = TRUE))
set.seed(2018+123*i)
original.X=X # Keeping a copy of X without any columns removed and before scaling
iInd=which(foldid==unique(foldid)[i])
if(length(iInd)<2){
iInd=c(iInd, iInd)
}
if(parm$scale=='ALL'){
X=scale(X)
}
if(parm$scale=='Patient')
{
sclidx= which(foldid==unique(foldid)[i])
if(length(sclidx)>1){
patient.col.means = colMeans(X[sclidx,]) # Storing means to apply same scaling to simulated data
}else{
patient.col.means = rep(0., dim(X)[2])
names(patient.col.means) = colnames(X)
}
for(ap in seq(length(unique(foldid))))
{
sclidx= which(foldid==unique(foldid)[ap])
if(length(sclidx)>1)
X[sclidx]=scale(X[sclidx], scale=F)
}
X=scale(X) #creates NA values for 10 features
rm_columns <- which(colSums(is.na(X)) > 0) # Getting the columns that are removed
X=X[, complete.cases(t(X))] #we remove those features
}
# Calculate Spearman's rank correlation and p-value
results <- vector("list", ncol(X))
for (j in seq_len(ncol(X))) {
res <- cor.test(X[, j], Y, method = "spearman", use = "pairwise.complete.obs", exact = FALSE)
results[[j]] <- data.frame(colname = colnames(X)[j], pvalue = res$p.value)
}
# Combine results into a data frame
pval_df <- bind_rows(results) %>%
mutate(pvalue = as.numeric(pvalue))
# Removing features with pvalue under a pval_threshold
fiter.out.features <- pval_df[pval_df$pvalue >= parm$pval_threshold, "colname"]
X <- X[,!(colnames(X) %in% fiter.out.features)]
rm_columns <- c(setNames(match(fiter.out.features, colnames(original.X)), fiter.out.features), rm_columns)
if (ncol(X) < 2){
X=cbind(X,rep(1, nrow(X)))
}
XX=X[-iInd,]
YY=Y[-iInd]
XT=X[iInd,]
fld=as.numeric(foldid[-iInd])
# Transforming the values of fld so that they range from 1 to 52 (avoiding one warning from glmet)
fld[fld>=i]=fld[fld>=i]-1
ret = list()
# Removed columns
ret$rm_cols <- rm_columns
# LASSO 1SE
cvglm = cv.glmnet(XX, YY,  standardize=F, alpha=1, foldid = fld)
ret$p1 = predict(cvglm, XT, s='lambda.1se')
ret$ptrain1 = predict(cvglm, XX, s='lambda.1se')
ret$coef = coef(cvglm, s='lambda.1se')[-1]
ret$model = cvglm
# Elastic Net
EN_cv = cv.glmnet(x = XX, y = YY, standardize=F, foldid = fld, alpha = parm$a)
ret$EN_p1 = predict(EN_cv, XT, s=EN_cv$lambda.min)
ret$EN_ptrain1 = predict(EN_cv, XX, s=EN_cv$lambda.min)
ret$EN_coef = coef(EN_cv, s=EN_cv$lambda.min)[-1]
# Ridge Regression
ridge_cv = cv.glmnet(x = XX, y = YY, standardize=F, foldid = fld, alpha = 0)
ret$ridge_p1 = predict(ridge_cv, XT, s=ridge_cv$lambda.min)
ret$ridge_ptrain1 = predict(ridge_cv, XX, s=ridge_cv$lambda.min)
ret$ridge_coef = coef(ridge_cv, s=ridge_cv$lambda.min)[-1]
# Adaptive LASSO
alasso1_cv = cv.glmnet(x = XX, y = YY, standardize=F, foldid = fld, alpha = 1,
penalty.factor = 1 / abs(ret$ridge_coef),
keep = TRUE)
ret$alasso_p1 = predict(alasso1_cv, XT, s=alasso1_cv$lambda.min)
ret$alasso_ptrain1 = predict(alasso1_cv, XX, s=alasso1_cv$lambda.min)
ret$alasso_coef = coef(alasso1_cv, s=alasso1_cv$lambda.min)[-1]
# Random Forest
rd_forest_cv = randomForest(x = XX, y = YY, standardize=F, importance=TRUE)
ret$rd_forest_p1 = predict(rd_forest_cv, XT)
ret$rd_forest_ptrain1 = predict(rd_forest_cv, XX)
ret$rd_forest_importance = rd_forest_cv$importance
if (predict.simulated.data){
# Getting X before scaling but only with the features which were filtered
unscaled.X = original.X[,!(colnames(original.X) %in% ret$rm_cols)]
means = colMeans(unscaled.X)
sds = colSds(unscaled.X)
# Filtering the samples of the patients in the test set
ret$median.simulated.TTL <- subset(median.simulated.data, grepl(paste0("P",unique(foldid)[i],"_"),sampleID))
ret$individual.simulated.TTL <- subset(individual.simulated.data, grepl(paste0("P",unique(foldid)[i],"_"),sampleID))
# Applying CYTOF preprocessing to the median simulated data
median_prepro_data <- dplyr::select(ret$median.simulated.TTL, -c(drug, sampleID, centroid, dose)) %>%
# Removing the columns which were removed in CYTOF
dplyr::select(intersect(colnames(original.X),colnames(ret$median.simulated.TTL)), -names(ret$rm_cols)) %>%
# Imputing the missing values with the medians of the corresponding CYTOF columns
dplyr::mutate(across(everything(), ~ ifelse(is.na(.), median(CYTOF[[cur_column()]], na.rm = TRUE), .))) %>%
# Applying the patient and gobal scaling applyed to the training data
dplyr::mutate(across(everything(), ~ (. - patient.col.means[[cur_column()]] - means[[cur_column()]])/sds[[cur_column()]])) %>%
# Converting to a matrix
as.matrix()
# Applying CYTOF preprocessing to the individual simulated data
individual_prepro_data <- dplyr::select(ret$individual.simulated.TTL, -c(drug, sampleID, centroid, dose)) %>%
# Removing the columns which were removed in CYTOF
dplyr::select(intersect(colnames(original.X),colnames(ret$individual.simulated.TTL)), -names(ret$rm_cols)) %>%
# Imputing the missing values with the medians of the corresponding CYTOF columns
dplyr::mutate(across(everything(), ~ ifelse(is.na(.), median(CYTOF[[cur_column()]], na.rm = TRUE), .))) %>%
# Applying the patient and gobal scaling applyed to the training data
dplyr::mutate(across(everything(), ~ (. - patient.col.means[[cur_column()]] - means[[cur_column()]])/sds[[cur_column()]])) %>%
# Converting to a matrix
as.matrix()
# Predictions
if (parm$predict.model == "Random.Forest"){
median_predictions <- predict(rd_forest_cv, median_prepro_data)
individual_predictions <- predict(rd_forest_cv, individual_prepro_data)
}else if(parm$predict.model == "ElasticNet"){
median_predictions <- predict(EN_cv, median_prepro_data, s=EN_cv$lambda.min)
individual_predictions <- predict(EN_cv, individual_prepro_data, s=EN_cv$lambda.min)
}else if(parm$predict.model == "Lasso.1se"){
median_predictions <- predict(cvglm, median_prepro_data, s='lambda.1se')
individual_predictions <- predict(cvglm, individual_prepro_data, s='lambda.1se')
}else if(parm$predict.model == "Ridge.Regression"){
median_predictions <- predict(ridge_cv, median_prepro_data, s=ridge_cv$lambda.min)
individual_predictions <- predict(ridge_cv, individual_prepro_data, s=ridge_cv$lambda.min)
}else if(parm$predict.model == "Adaptive.Lasso"){
median_predictions <- predict(alasso1_cv, median_prepro_data, s=alasso1_cv$lambda.min)
individual_predictions <- predict(alasso1_cv, individual_prepro_data, s=alasso1_cv$lambda.min)
}else{
median_predictions <- rep(NA, dim(median_prepro_data)[0])
individual_predictions <- rep(NA, dim(individual_prepro_data)[0])
}
ret$median.simulated.TTL <-cbind(dplyr::select(ret$median.simulated.TTL, c(drug, sampleID, centroid, dose)),
median_predictions)
ret$individual.simulated.TTL <-cbind(dplyr::select(ret$individual.simulated.TTL, c(drug, sampleID, centroid, dose)),
individual_predictions)
}
return(ret)
}
# Getting the intersection of all selected features by the 5 models
best.features <- unique(AllPenDoseresponse$feature)
for (model.name in names(best_pval_thresholds)){
feature.index <- get.feature.index(model.name)
selected.features <- feature.index[feature.index[,"model_index"]>0, "feature"]
best.features <- intersect(best.features, selected.features)
}
# Saving the list of features selected by all models
save(feature.index, file=paste0(out_path, "/feature_index.rda"))
# Extracting the CYTOF dataset restricted to these features
restricted.CYTOF <- dplyr::select(CYTOF, best.features)
######################### WARNING : THIS CELL TAKES 1H30 TO RUN ! #########################
# Building the best models and storing them and their predictions
for (model.name in names(best_pval_thresholds)){
# xxx parameter
parm=list()
parm$scale='Patient'
parm$a=0.5
npt=length(unique(Id))
parm$predict.model=model.name
parm$pval_threshold=1000
# Opening backend-configuration
cl <- makeSOCKcluster(detectCores())
registerDoSNOW(cl)
# Getting models and predictions
prdC=foreach(i=seq(npt),.packages = c("dplyr", "tibble", "matrixStats")) %dopar% xxx(data.matrix(restricted.CYTOF), Yh, Id, i, parm, TRUE)
list_preds<-aggregation.of.predictions(prdC)
# Closing backend configuration
stopCluster(cl)
# Saving the models and their predictions
save(prdC, file=paste0(out_path, "/", model.name," on best features.rda"))
save(list_preds, file=paste0(out_path, "/", model.name," on best features predictions.rda"))
}
CYTOF
######################### WARNING : THIS CELL TAKES 1H30 TO RUN ! #########################
# Building the best models and storing them and their predictions
for (model.name in names(best_pval_thresholds)){
# xxx parameter
parm=list()
parm$scale='Patient'
parm$a=0.5
npt=length(unique(Id))
parm$predict.model=model.name
parm$pval_threshold=1000
# Opening backend-configuration
cl <- makeSOCKcluster(detectCores())
registerDoSNOW(cl, .export = c("CYTOF"))
# Getting models and predictions
prdC=foreach(i=seq(npt),.packages = c("dplyr", "tibble", "matrixStats")) %dopar% xxx(data.matrix(restricted.CYTOF), Yh, Id, i, parm, TRUE)
list_preds<-aggregation.of.predictions(prdC)
# Closing backend configuration
stopCluster(cl)
# Saving the models and their predictions
save(prdC, file=paste0(out_path, "/", model.name," on best features.rda"))
save(list_preds, file=paste0(out_path, "/", model.name," on best features predictions.rda"))
}
######################### WARNING : THIS CELL TAKES 1H30 TO RUN ! #########################
# Building the best models and storing them and their predictions
for (model.name in names(best_pval_thresholds)){
# xxx parameter
parm=list()
parm$scale='Patient'
parm$a=0.5
npt=length(unique(Id))
parm$predict.model=model.name
parm$pval_threshold=1000
# Opening backend-configuration
cl <- makeSOCKcluster(detectCores())
registerDoSNOW(cl)
# Getting models and predictions
prdC=foreach(i=seq(npt),.packages = c("dplyr", "tibble", "matrixStats"), .export = c("CYTOF")) %dopar% xxx(data.matrix(restricted.CYTOF), Yh, Id, i, parm, TRUE)
list_preds<-aggregation.of.predictions(prdC)
# Closing backend configuration
stopCluster(cl)
# Saving the models and their predictions
save(prdC, file=paste0(out_path, "/", model.name," on best features.rda"))
save(list_preds, file=paste0(out_path, "/", model.name," on best features predictions.rda"))
}
# X axis
x_axis="DOS" # EGA or DOS
# Plotting the results of the models on best features
for (model.name in names(best_pval_thresholds)){
load(paste0(out_path, "/", model.name," on best features predictions.rda"))
y_pred <- list_preds[[model.name]]
pdf(file=paste0(plot_path, "/", model.name, " on best features on ",x_axis," outcomes.pdf"))
plot.model.results(y_pred[preterm_rows], Yh[preterm_rows], EGA[preterm_rows], paste0(model.name, " on preterm"), x_axis)
plot.model.results(y_pred[-preterm_rows], Yh[-preterm_rows], EGA[-preterm_rows], paste0(model.name, " on term"), x_axis)
plot.model.results(y_pred, Yh, EGA, paste0(model.name, " on all"), x_axis)
dev.off()
}
get.feature.index <- function(model.name, on.best.feature=FALSE){
#Importing selected model and its predictions
if (on.best.feature){
# list_preds
load(paste0(out_path, "/", model.name," on best features predictions.rda"))
# prdC
load(paste0(out_path, "/", model.name," on best features.rda"))
}else{
# list_preds
load(paste0(out_path, "/best ", model.name," predictions.rda"))
# prdC
load(paste0(out_path, "/best ", model.name,".rda"))
}
# key to fetch the model's coefs in prdC
if (model.name == "Random.Forest"){
coef_key <- "rd_forest_importance"
}else if(model.name == "ElasticNet"){
coef_key <- "EN_coef"
}else if(model.name == "Lasso.1se"){
coef_key <- "coef"
}else if(model.name == "Ridge.Regression"){
coef_key <- "ridge_coef"
}else if(model.name == "Adaptive.Lasso"){
coef_key <- "alasso_coef"
}else{
coef_key <- NULL
}
# Creation of a vector of the columns that are removed when building the model.
rm_cols <- c()
for (iter in seq(prdC)){
rm_cols <- c(rm_cols, prdC[[iter]]$rm_cols)
}
rm_cols <- unique(rm_cols)
# Creation of the feature index
if (model.name=="Random.Forest"){
feature.index <- data.frame(feature = character(),
pval = double(),
mean_abs_coef = double(),
model_index = double(),
stringsAsFactors = FALSE)
}else{
feature.index <- data.frame(feature = character(),
pval = double(),
mean_relative_node_purity = double(),
model_index = double(),
stringsAsFactors = FALSE)
}
cols <- colnames(CYTOF[,-rm_cols])
for (i in seq(1, length(cols))){
# Name of the feature
feature <- cols[i]
# P value based on a spearman test
pval <- cor.test(Yh, CYTOF[[feature]], method = 'spearman', exact = FALSE)$p.value
# Coefficient of relative node purity given by the model
if (model.name=="Random.Forest"){
# Collecting all the node purity of the selected features
relative_node_purity <- c()
for (iter in seq(prdC)){
relative_node_purity[iter] <- prdC[[iter]][[coef_key]][feature,"IncNodePurity"]/
max(prdC[[iter]][[coef_key]][,"IncNodePurity"])
}
# Mean of the relative node purity
mean_relative_node_purity <- mean(relative_node_purity)
# Adding the feature to feature.index
feature.index <- rbind(feature.index,
data.frame(feature=feature,
pval=pval,
mean_relative_node_purity=mean_relative_node_purity,
model_index=-mean_relative_node_purity*log10(pval),
stringsAsFactors = FALSE))
}else{
# Collecting all the absolute values of the coefficients of the model
coefs <- c()
for (iter in seq(prdC)){
coefs[iter] <- abs(prdC[[iter]][[coef_key]][i])
}
# Mean of the coefficients
mean_abs_coef <- mean(coefs)
# Adding the feature to feature.index
feature.index <- rbind(feature.index,
data.frame(feature=feature,
pval=pval,
mean_abs_coef=mean_abs_coef,
model_index=-abs(mean_abs_coef)*log10(pval),
stringsAsFactors = FALSE))
}
}
feature.index <- feature.index %>% arrange(desc(model_index))
}
for (model.name in names(best_pval_thresholds)){
feature.index <- get.feature.index(model.name, on.best.feature = TRUE)
selected.features <- feature.index[feature.index[,"model_index"]>0, "feature"]
print(paste0(model.name, " : ", length(selected.features), " selected features"))
}
for (model.name in names(best_pval_thresholds)){
feature.index <- get.feature.index(model.name, on.best.feature = FALSE)
selected.features <- feature.index[feature.index[,"model_index"]>0, "feature"]
print(paste0(model.name, " : ", length(selected.features), " selected features"))
}
get.feature.index <- function(model.name, on.best.feature=FALSE){
#Importing selected model and its predictions
if (on.best.feature){
# list_preds
load(paste0(out_path, "/", model.name," on best features predictions.rda"))
# prdC
load(paste0(out_path, "/", model.name," on best features.rda"))
}else{
# list_preds
load(paste0(out_path, "/best ", model.name," predictions.rda"))
# prdC
load(paste0(out_path, "/best ", model.name,".rda"))
}
# key to fetch the model's coefs in prdC
if (model.name == "Random.Forest"){
coef_key <- "rd_forest_importance"
}else if(model.name == "ElasticNet"){
coef_key <- "EN_coef"
}else if(model.name == "Lasso.1se"){
coef_key <- "coef"
}else if(model.name == "Ridge.Regression"){
coef_key <- "ridge_coef"
}else if(model.name == "Adaptive.Lasso"){
coef_key <- "alasso_coef"
}else{
coef_key <- NULL
}
# Creation of a vector of the columns that are removed when building the model.
rm_cols <- c()
for (iter in seq(prdC)){
rm_cols <- c(rm_cols, prdC[[iter]]$rm_cols)
}
rm_cols <- unique(rm_cols)
# Creation of the feature index
if (model.name=="Random.Forest"){
feature.index <- data.frame(feature = character(),
pval = double(),
mean_abs_coef = double(),
model_index = double(),
stringsAsFactors = FALSE)
}else{
feature.index <- data.frame(feature = character(),
pval = double(),
mean_relative_node_purity = double(),
model_index = double(),
stringsAsFactors = FALSE)
}
cols <- colnames(CYTOF[,-rm_cols])
for (i in seq(1, length(cols))){
# Name of the feature
feature <- cols[i]
# P value based on a spearman test
pval <- cor.test(Yh, CYTOF[[feature]], method = 'spearman', exact = FALSE)$p.value
# Coefficient of relative node purity given by the model
if (model.name=="Random.Forest"){
# Collecting all the node purity of the selected features
relative_node_purity <- c()
for (iter in seq(prdC)){
relative_node_purity[iter] <- prdC[[iter]][[coef_key]][feature,"IncNodePurity"]/
max(prdC[[iter]][[coef_key]][,"IncNodePurity"])
}
# Mean of the relative node purity
mean_relative_node_purity <- mean(relative_node_purity)
# Adding the feature to feature.index
feature.index <- rbind(feature.index,
data.frame(feature=feature,
pval=pval,
mean_relative_node_purity=mean_relative_node_purity,
model_index=-mean_relative_node_purity*log10(pval),
stringsAsFactors = FALSE))
}else{
# Collecting all the absolute values of the coefficients of the model
coefs <- c()
for (iter in seq(prdC)){
coefs[iter] <- abs(prdC[[iter]][[coef_key]][i])
}
# Mean of the coefficients
mean_abs_coef <- mean(coefs)
# Adding the feature to feature.index
feature.index <- rbind(feature.index,
data.frame(feature=feature,
pval=pval,
mean_abs_coef=mean_abs_coef,
model_index=-abs(mean_abs_coef)*log10(pval),
stringsAsFactors = FALSE))
}
}
feature.index <- feature.index %>% arrange(desc(model_index))
}
# Getting the intersection of all selected features by the 5 models
best.features <- unique(AllPenDoseresponse$feature)
for (model.name in names(best_pval_thresholds)){
feature.index <- get.feature.index(model.name)
selected.features <- feature.index[feature.index[,"model_index"]>0, "feature"]
best.features <- intersect(best.features, selected.features)
}
load(paste0(out_path, "/best ", model.name," predictions.rda"))
load(paste0(out_path, "/best ", model.name,".rda"))
